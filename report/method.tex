\section{Method}

\subsection{Text Features}
Feature extraction from a text is the process of finding a vector that
represents the text. There are a lot of different features that can be extracted
and we use several of them. Specifically we use some character level features,
some word level features and som \gls{POS} tagging features. In this section
we will define the different features we use. The specific features used in
different experiments will be described under those experiments.

N-grams are subsequences extracted from a sequence of tokens. For example
3-grams is all subsequences of length three of a given sequence. For example
using individual characters as tokens all \textit{character 3-grams} of the
string "hello" is "hel", "ell" and "llo". We use several different types of
n-grams in different experiments including character n-grams, word n-grams,
special character n-grams and \gls{POS} tagging n-grams. Word n-grams are
subsequences of words, special character n-grams are subsequences of characters
with alphanumeric characters removed, \gls{POS} tagging n-grams are subsequences
of \gls{POS} tags. A special case of n-grams is 1-grams which is just a count of
the different tokens in a sequence. We will refer to 1-grams as frequencies.

\subsection{Delta Method}
We have chosen to use the Delta method as a baseline method for our other
implementations. The Delta method is described by \cite{evert2015towards} and
consist of extracting word frequencies, applying a linear transformation to
those frequencies and using \gls{KNN} with different distance metrics. There are
a number of parameters to choose. First of all the number of different words to
find frequencies for has to be chosen (it was originally chosen at 150 words
\cite{evert2015towards}). Then the linear transformation can be chosen, the
usual transformation is a normalization to zero mean unit variance. And finally
the distance metric can be chosen.

\subsection{Generalising Random Forest}
In addition to the delta method we chose to use the Random Forest approach
suggested by \cite{pacheco2015}. In our implementation we use different
features than in the their proposal. The idea of the method is to learn a
general difference between feature vectors of texts written by the same author
and feature vectors written by the different authors. The generalization is
obtained by combining the vectors of known texts with vectors of unknown
text and training on that combination instead of on the raw vectors. In
\cite{pacheco2015} the combining function is,

\begin{equation}
    \left\langle
        \dfrac{(A_i-U_i)^2+1}{(B-U_i)^2+1}|i \in [0,\dots, N)
    \right\rangle,
\end{equation}

where $A_i$ is the $i$'th author-specific feature vector, $B$ is a \gls{UBM}
describing a general author independent text and $U_i$ is the feature vector of
the $i$'th unknown text.

The \gls{UBM} is meant to represent the features of an author independent text.
It is computed by concatenating all texts in the training dataset and computing
features from that resulting text. Since multiple authors is then part of the
text we are computing features from, the assumption is that the author specific
features will be averaged out and the \gls{UBM} will represent the features of
an author independent text. The addition of 1 in the model prevent division
by zero. Since 1 is added both in the numerator and the denominator it does
not otherwise change the result. The squaring of $(A_i - U_i)$ and $(B - U_i)$
prevents negative values. Therefore each value in the resulting encoded feature
vector is in the range $[0; \inf[$.

Let's examine what the above equation describes. Fix any specific $i$ and let
$A$ be $A_i$ and $U$ be $U_i$ then for each feature $k$ we compute,

\begin{equation}
    R_k = \frac{(A_k-U_k)^2+1}{(B_k-U_k)^2+1},
\end{equation}

The $k$'th feature in each of the vectors is the same feature just extracted
from different texts. When the feature of the unknown text $U_k$ is closer to
$A_k$ than $B_k$ the numerator in the fraction will be greater than the
denominator giving us something in the range $[0; 1]$. When the feature of the
unknown text $U_k$ is closer to $B_k$ than $A_k$ the numerator will be lesser
than the denominator and we will therefore get a value in the interval
$[1; \infty[$. That results in $R$ being a vector containing values from 0 to
$\infty$ where it is between 0 and 1 whenever a feature is closer to the author
specific text than the universal text and greater than 1 otherwise.

The random forest algorithm is then trained on these encoded feature vectors
where it is supposed to learn a general difference between feature vectors of
the same authors and feature vectors of different authors.

\subsection{Extended Delta}
TODO: Experiment with different features.

\subsection{Author Specific SVM} \label{subsec:author_specific_svm}
We implemented an approach using \gls{SVM}'s inspired by \cite{hansen2014}. The
approach is only applicable to problems with more than a single text per
unknown author. The classification in this approach is done by training an \gls{SVM}
classifier on all known texts of an author and an equal number of texts from
other authors. Then the unknown text is given to the \gls{SVM} and is classified
either as belonging to the same author or as belonging to a different author.

If there is only a single known text available for an author it does not make
sense to train an \gls{SVM} since there is simply to little data.

\subsection{Author Specific Random Forest}
We implemented an approach using Random Forests trained to recognise a single
authors texts. The approach is exactly the same as
\ref{subsec:author_specific_svm} except that it uses a random forest instead of
an \gls{SVM}.

\subsection{Experiments}
In this section we describe the different experiments we have performed.
We have tested the different methods we have implemented with different
features and on different datasets. In our experiments we use data from PAN
2013 \footnote{http://pan.webis.de/clef13/pan13-web/index.html} and PAN 2015
\footnote{http://pan.webis.de/clef15/pan15-web/index.html}. The PAN 2013 data
consist of texts from English, Greek and Spanish authors. We work only on the
English texts which consist of texts from 10 authors. There is a number (between
1 and 10) known texts from each author and a single unknown text. The task is
given the known texts of an author to determine whether or not the unknown text
is written by the same author or not.

The PAN 2015 data consist of texts by authors in English, Dutch, Greek and
Spanish. Again we only work with English texts. Unlike the 2013 dataset there is
only a single known text for each author and a single unknown text. There is
therefore much less known data available for each author which makes the
verification harder. In the 2015 dataset there is 100 \textit{problems} in which
some of the known texts are the same (i.e. there is not 100 authors).

To generate metadata about English texts we use the Brown dataset
\footnote{http://clu.uni.no/icame/brown/bcm-los.html}. The brown dataset
contains more than 1,000,000 words across different genres and is therefore
perfect to use for our datasets. We specifically use the dataset to identify
the most frequently used n-grams (of all kinds). If we were to use our training
data to generate that we would risk having a bias towards our specific training
dataset.

\subsubsection{Delta Method}
In the delta method we work only with word frequencies as originally proposed.
As the linear function we normalize to 0 mean and unit variance and as features
we use the $n$ most frequent words. We get the most frequent words by using the
brown dataset. In the \gls{KNN} part we use the Manhatten distance and only a
single nearest neighbour since in one of the datasets we have only 1 text for
each author. To classify the unknown texts as either written by or not written
by the author we train a \gls{KNN} for each unknown text. Each classifier is
trained with a known text from the author in question and $m$ other random
texts. If the unknown text is classified as belonging to one of the $m$ random
authors instead of the author in question we report that the unknown text is not
written by the author. If the text is classified as belonging to the author in
question we classify it as being written by the author.

We chose the number of most frequent words $n$ and number of opposing
authors $m$ by trying different configurations in a grid and choosing the
best values. Each configuration is tried 100 times since random authors are
chosen in each run. On the training dataset we obtained the results shown in
Figure \ref{fig:delta_pan_2013_res} for the PAN 2013 data and in Figure
\ref{fig:delta_pan_2015_res} for the PAN 2015 data. For PAN 2013 the results are
generally better since there is more text available and the best accuracy were
obtained when using the 300 most frequent words and 4 opposing authors. For PAN
2015 the best result is obtained when using the 200 most frequent words and 1
opposing authors.

\begin{figure}
    \centering
    \begin{tabular}{c|lccccc}
               &                   & $n=100$ & $n=200$ & $n=300$ & $n=400$ & $n=500$ \\
        \hline
        $m=1$  & \textbf{Accuracy} & 0.62093 & 0.64437 & 0.65062 & 0.66718 & 0.66281 \\
               & \textbf{TPR}      & 0.75812 & 0.79562 & \textbf{0.80812} & 0.79750 & 0.77500 \\
               & \textbf{TNR}      & 0.48375 & 0.49312 & 0.49312 & 0.53687 & 0.55062 \\
        \hline
        $m=2$  & \textbf{Accuracy} & 0.65375 & 0.68562 & 0.69593 & 0.68968 & 0.68250 \\
               & \textbf{TPR}      & 0.63250 & 0.71875 & 0.74000 & 0.70062 & 0.67125 \\
               & \textbf{TNR}      & 0.67500 & 0.65250 & 0.65187 & 0.67875 & 0.69375 \\
        \hline
        $m=3$  & \textbf{Accuracy} & 0.66250 & 0.68187 & 0.69687 & 0.69250 & 0.69843 \\
               & \textbf{TPR}      & 0.55937 & 0.64125 & 0.68375 & 0.65437 & 0.63375 \\
               & \textbf{TNR}      & 0.76562 & 0.72250 & 0.71000 & 0.73062 & 0.76312 \\
        \hline
        $m=4$  & \textbf{Accuracy} & 0.66312 & 0.68656 & \textbf{0.70062} & 0.68062 & 0.68281 \\
               & \textbf{TPR}      & 0.49875 & 0.61125 & 0.65125 & 0.61875 & 0.57562 \\
               & \textbf{TNR}      & 0.82750 & 0.76187 & 0.75000 & 0.74250 & 0.79000 \\
        \hline
        $m=5$  & \textbf{Accuracy} & 0.66343 & 0.69468 & 0.69250 & 0.66937 & 0.68437 \\
               & \textbf{TPR}      & 0.46687 & 0.59375 & 0.61812 & 0.57500 & 0.54937 \\
               & \textbf{TNR}      & 0.86000 & 0.79562 & 0.76687 & 0.76375 & 0.81937 \\
        \hline
        $m=6$  & \textbf{Accuracy} & 0.63531 & 0.67437 & 0.69406 & 0.67312 & 0.66718 \\
               & \textbf{TPR}      & 0.39937 & 0.55125 & 0.59750 & 0.56750 & 0.50312 \\
               & \textbf{TNR}      & 0.87125 & 0.79750 & 0.79062 & 0.77875 & 0.83125 \\
        \hline
        $m=7$  & \textbf{Accuracy} & 0.63843 & 0.67906 & 0.68437 & 0.67000 & 0.66562 \\
               & \textbf{TPR}      & 0.37875 & 0.53812 & 0.58500 & 0.54687 & 0.49625 \\
               & \textbf{TNR}      & 0.89812 & 0.82000 & 0.78375 & 0.79312 & 0.83500 \\
        \hline
        $m=8$  & \textbf{Accuracy} & 0.63406 & 0.69281 & 0.68156 & 0.65218 & 0.67156 \\
               & \textbf{TPR}      & 0.36937 & 0.55062 & 0.56250 & 0.52250 & 0.50000 \\
               & \textbf{TNR}      & 0.89875 & 0.83500 & 0.80062 & 0.78187 & 0.84312 \\
        \hline
        $m=9$  & \textbf{Accuracy} & 0.63781 & 0.68031 & 0.66437 & 0.66656 & 0.67031 \\
               & \textbf{TPR}      & 0.36625 & 0.51937 & 0.53000 & 0.52562 & 0.47375 \\
               & \textbf{TNR}      & \textbf{0.90937} & 0.84125 & 0.79875 & 0.80750 & 0.86687 \\
        \hline
        $m=10$ & \textbf{Accuracy} & 0.62562 & 0.68781 & 0.68343 & 0.67687 & 0.66000 \\
               & \textbf{TPR}      & 0.34625 & 0.51375 & 0.54937 & 0.53125 & 0.46312 \\
               & \textbf{TNR}      & 0.90500 & 0.86187 & 0.81750 & 0.82250 & 0.85687
    \end{tabular}
    \caption{Accuracy, \gls{TPR} and \gls{TNR} on different number of most
        frequent words $n$ and different number of opposing authors $m$ for the
        Delta Method. Each number is an average of 100 runs since there is
        randomness involved when picking the opposing authors. The test is run
        on the PAN 2013 dataset. Maximum values for both Accuracy, \gls{TPR} and
        \gls{TNR} is shown in bold.}
    \label{fig:delta_pan_2013_res}
\end{figure}

\begin{figure}
    \centering
    \begin{tabular}{c|ccccc}
               & $n=100$ & $n=200$ & $n=300$ & $n=400$ & $n=500$ \\
        \hline
        $m=1$  & \textbf{Accuracy} &0.5695000000000001,0.5874,0.5516
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=2$  & \textbf{Accuracy} &0.5681,0.42219999999999996,0.7140000000000001
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=3$  & \textbf{Accuracy} &0.5539999999999999,0.3248,0.7831999999999999
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=4$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=5$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=6$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=7$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=8$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=9$  & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
        \hline
        $m=10$ & \textbf{Accuracy} &
               & \textbf{TPR}      &
               & \textbf{TNR}      &
    \end{tabular}
    \caption{Accuracy on different number of most frequent words $n$ and
        different number of opposing authors $m$ for the Delta Method. Each
        number is an average of 100 runs since there is randomness involved when
        picking the opposing authors. The test is run on the PAN 2015 dataset.}
    \label{fig:delta_pan_2015_res}
\end{figure}
%../../data/pan_2015   100   4   Brown   (0.5458999999999999,0.25920000000000004,0.8326)
%../../data/pan_2015   100   5   Brown   (0.5352,0.21,0.8604)
%../../data/pan_2015   100   6   Brown   (0.5274999999999999,0.17980000000000002,0.8752)
%../../data/pan_2015   100   7   Brown   (0.5279000000000003,0.1624,0.8934000000000001)
%../../data/pan_2015   100   8   Brown   (0.5234000000000002,0.1482,0.8986)
%../../data/pan_2015   100   9   Brown   (0.5193,0.1304,0.9081999999999999)
%../../data/pan_2015   100   10   Brown   (0.5178,0.1186,0.917)
%../../data/pan_2015   200   1   Brown   (0.6023999999999999,0.6466,0.5582)
%../../data/pan_2015   200   2   Brown   (0.5897000000000001,0.46740000000000004,0.7120000000000001)
%../../data/pan_2015   200   3   Brown   (0.5751000000000001,0.3688,0.7814)
%../../data/pan_2015   200   4   Brown   (0.5639,0.2994,0.8284)
%../../data/pan_2015   200   5   Brown   (0.5543,0.2492,0.8593999999999999)
%../../data/pan_2015   200   6   Brown   (0.5482000000000001,0.2184,0.878)
%../../data/pan_2015   200   7   Brown   (0.5418999999999998,0.1916,0.8922)
%../../data/pan_2015   200   8   Brown   (0.5357000000000003,0.1744,0.897)
%../../data/pan_2015   200   9   Brown   (0.5334000000000002,0.1522,0.9146)
%../../data/pan_2015   200   10   Brown   (0.5255000000000004,0.1376,0.9134)
%../../data/pan_2015   300   1   Brown   (0.5621,0.6175999999999999,0.5065999999999999)
%../../data/pan_2015   300   2   Brown   (0.5647000000000001,0.4572,0.6722)
%../../data/pan_2015   300   3   Brown   (0.5622000000000004,0.36060000000000003,0.7637999999999999)
%../../data/pan_2015   300   4   Brown   (0.5456000000000002,0.29460000000000003,0.7966)
%../../data/pan_2015   300   5   Brown   (0.5415000000000001,0.24420000000000003,0.8388)
%../../data/pan_2015   300   6   Brown   (0.5370999999999999,0.218,0.8562000000000001)
%../../data/pan_2015   300   7   Brown   (0.5324000000000001,0.19440000000000002,0.8704000000000001)
%../../data/pan_2015   300   8   Brown   (0.5245999999999998,0.1618,0.8874)
%../../data/pan_2015   300   9   Brown   (0.5206,0.152,0.8892)
%../../data/pan_2015   300   10   Brown   (0.5226,0.1396,0.9056000000000001)
%../../data/pan_2015   400   1   Brown   (0.5726999999999999,0.622,0.5234000000000001)
%../../data/pan_2015   400   2   Brown   (0.5729000000000001,0.4534,0.6923999999999999)
%../../data/pan_2015   400   3   Brown   (0.5685000000000002,0.3666,0.7704000000000001)
%../../data/pan_2015   400   4   Brown   (0.5558,0.29,0.8216)
%../../data/pan_2015   400   5   Brown   (0.5629,0.2586,0.8672)
%../../data/pan_2015   400   6   Brown   (0.5553,0.231,0.8795999999999999)
%../../data/pan_2015   400   7   Brown   (0.5455000000000002,0.1866,0.9044)
%../../data/pan_2015   400   8   Brown   (0.5489999999999999,0.1776,0.9204000000000001)
%../../data/pan_2015   400   9   Brown   (0.5422999999999999,0.157,0.9276000000000001)
%../../data/pan_2015   400   10   Brown   (0.5408000000000001,0.1366,0.945)
%../../data/pan_2015   500   1   Brown   (0.5617000000000002,0.6102000000000001,0.5132)
%../../data/pan_2015   500   2   Brown   (0.5603000000000001,0.4464,0.6742)
%../../data/pan_2015   500   3   Brown   (0.5538000000000001,0.3382,0.7694)
%../../data/pan_2015   500   4   Brown   (0.5471,0.278,0.8162)
%../../data/pan_2015   500   5   Brown   (0.5496000000000002,0.2422,0.857)
%../../data/pan_2015   500   6   Brown   (0.5426000000000001,0.20739999999999997,0.8778)
%../../data/pan_2015   500   7   Brown   (0.5453000000000001,0.1902,0.9004000000000001)
%../../data/pan_2015   500   8   Brown   (0.5341999999999999,0.15560000000000002,0.9128000000000001)
%../../data/pan_2015   500   9   Brown   (0.5346000000000001,0.1506,0.9186)
%../../data/pan_2015   500   10   Brown   (0.5315000000000001,0.1294,0.9336)


%\begin{figure}
    %\centering
    %\begin{tabular}{c|ccccc}
               %& $n=100$ & $n=200$ & $n=300$ & $n=400$ & $n=500$ \\
        %\hline
        %$m=1$  & 0.57370 & \textbf{0.59350} & 0.56730 & 0.56470 & 0.55650 \\
        %$m=2$  & 0.56800 & 0.58400 & 0.56530 & 0.56960 & 0.55190 \\
        %$m=3$  & 0.55369 & 0.57580 & 0.55540 & 0.56010 & 0.54990 \\
        %$m=4$  & 0.54259 & 0.56360 & 0.55140 & 0.56590 & 0.54599 \\
        %$m=5$  & 0.53650 & 0.55890 & 0.54089 & 0.55950 & 0.54450 \\
        %$m=6$  & 0.52900 & 0.54680 & 0.53280 & 0.55170 & 0.53770 \\
        %$m=7$  & 0.52599 & 0.53750 & 0.52879 & 0.54850 & 0.53629 \\
        %$m=8$  & 0.52169 & 0.53450 & 0.52950 & 0.54560 & 0.53740 \\
        %$m=9$  & 0.51999 & 0.53420 & 0.52490 & 0.54829 & 0.53620 \\
        %$m=10$ & 0.51960 & 0.52660 & 0.51979 & 0.54470 & 0.53510
    %\end{tabular}
    %\caption{Accuracy on different number of most frequent words $n$ and
        %different number of opposing authors $m$ for the Delta Method. Each
        %number is an average of 100 runs since there is randomness involved when
        %picking the opposing authors. The test is run on the PAN 2015 dataset.}
    %\label{fig:delta_pan_2015_res}
%\end{figure}

% TODO: Describe number of trees and other parameters.
% TODO: Tables of tests.
\subsubsection{Generalising Random Forest}
TBA


In the test of our random forest implementation we used a combination
of different features. We used the 20 most frequent character
2-grams, the 20 most frequent 3-grams, the 10 most frequent
word 3-grams and the 10 most frequent \gls{POS} tag 3-grams.
We used the random forest implementation from \texttt{sklearn}
\footnote{http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}.

We tested our solution by splitting the training data into two sets a set used
for training and a set used for testing. For this test we split with 80\% being
the training set, and the rest being the test set. We computed the average of
100 tests to account for randomness. The accuracy on the 2015 dataset resulted
only in 0.48 accuracy.

\subsection{Extended Delta}
TODO: Experiment with different features.

\subsection{Author Specific SVM} \label{subsec:author_specific_svm}
In this approach we work with a mixture of different features. We use the 500
most frequent 3-, 4- and 5-character-grams, the 100 most frequent 3- an
4-word-grams, the 20 most frequent 2-, 3- and 4-postag-grams. The most frequent
grams is found in the brown text corpus. We run only on the PAN 2013 dataset
since 2015 contains only a single known text per author and it would therefore
not make sense to use this method. We use the \textit{sklearn} implementation of
\gls{SVM}'s which internally use \textit{libsvm}.

For each author $a$ in the 2013 dataset we compute features for all known texts
$k$ and give them the class 1. Then we choose the $|k|$ number of random texts
written by other authors and give them the class 0. We then train an \gls{SVM}
classifier on the features and classes generated and use it to predict either 0
or 1 for the unknown text. The \gls{SVM} use a rbf kernel with $C=1$ and
$\gamma = frac{1}{(2|k|)}$. Using that approach we get an average accuracy over
100 runs of 0.736.

\subsection{Author Specific Random Forest}
In this approach we use the same features as in
\ref{subsec:author_specific_svm}. The only difference is that we train a random
forest instead of an \gls{SVM} on the data. The forest has 7 decision trees and
we use the \textit{sklearn} implementation. Using that approach we get an
accurate accuracy over 100 runs of 0.607.
