\section{Conclusion} \label{sec:conclusion}

We have presented a collection of machine learning and distance based solutions
to the PAN 2013, and PAN 2015 tasks. We beat our baseline (the Delta Method) on
both datasets. We implemented solutions that we applied to both datasets and
solutions specifically made for one dataset.

We obtained third place in the PAN 2013 competition using our \gls{SVM}
solution. While our best results on the PAN 2015 set, the Extended Delta
method, did beat the baseline as well, it didn't score as high on the PAN 2015
scoreboard. It scored 8'th in that year of the PAN competition.

We have experimented with several different types of features and we now have
a good idea of which features better represents texts. Specifically stop-words
and special characters have a far greater impact on authorship verification,
than for example content specific words.

We have experimented with how the amount of data you have available influences
the problem of authorship verification. The PAN 2013 dataset had many more words
available per author and the accuracies we were able to obtain reflected that
fact. Both of the solutions that performed better than our solution on the PAN
2013 dataset used extra texts besides the ones given to train their solutions.
That supports our suspicion that the amount of data there is available
is the greatest predictor of the final score of a solution.
